# Отчет по лабораторной работе
## по курсу "Искусственый интеллект"

## Классификация

### Студент: Сахарин Н.А.

## Результат проверки

| Преподаватель     | Дата         |  Оценка       |
|-------------------|--------------|---------------|
| Самир Ахмед       |              |               |

> *Комментарии проверяющих*

## Тема работы
  Реализовать алгоритм выявляющий взаимосвязанные сообщения на языке Python. Подобрать или создать датасет и обучить модель. Продемонстрировать зависимость качества кластеризации от объема, качества выборки и числа кластеров. Продемонстрировать работу вашего алгоритма. Обосновать выбор данного алгоритма машинного обучения. Построить облако слов для центров кластеров(wordcloud).

## Отчет по ходу работы
  Рассматриваемую задачу можно поделить на две части.
  1) Обработка исходного текста, получение матрицы признаков (feature matrix) и вектора классов. Изначально задан список текстов. Для каждого текста известно, содержит от негативный отзыв (в алгоритме программы обозначается 0) или позитивный (обозначается 1). Таким образом каждому тексту поставлен в соответствие один из двух классов. Для каждого слова в тексте необходимо выделить главную часть. Так, например, словa 'значимо', 'значимый' и 'значимость' должны выражаться в результирующей матрице одним столбцом, а не тремя. Так как мы будем пользоваться предположением, которые упрощенно можно выразить так - однокоренные слова близкие по смыслу представляют из себя один и тот же принак.
```python
from nltk.stem.snowball import SnowballStemmer
>>> st = SnowballStemmer('russian')
>>> st.stem('значение')
'значен'
>>> st.stem('значимость')
'значен'
>>> st.stem('значимый')
'значим'
```
  Таким образом, обработка текста включает в себя стемминг (stemming).
  2)
```python
[nltk_data] Downloading package movie_reviews to
[nltk_data]     /home/nikita/nltk_data...
[nltk_data]   Package movie_reviews is already up-to-date!
[nltk_data] Downloading package stopwords to /home/nikita/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
naive bayes classifier:
accuracy_score = 0.8216666666666667
sklearn.naive_bayes.MultinomialNB:
accuracy_score = 0.82
```

## Выводы
